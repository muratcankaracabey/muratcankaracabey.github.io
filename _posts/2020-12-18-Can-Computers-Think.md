---
layout: post
title: Can Computers Think?
comments: true
---
*This is the essay that I've written two years ago for my admission to Informatics department of Technical University of Munich. There were a couple of predefined topics to write about and I picked the question on the title since it had seemed very interesting for me. I tried to summarize the discussion around the question "Can Computers Think?" by obeying the 1000 words quota and finally come up with a conclusion. Since it was a result of a few weeks research, it might not be perfect but I still believe that this essay was able to summarize most of the directions one can follow while investigating the thinking capability of computers. Enjoy it.*

We need to delve into some of the interdisciplinaries while approaching such a controversial question. This is because we might find ourselves thinking about the notion of thinking, asking ourselves “what is consciousness?” or “how does my mind work?” along with questioning how a computer can think.

Thinking is “the action of using one's mind to produce thoughts” according to merriam-webster<a id="reverse1"></a><a href="#1">$^1$</a>. Hence, we can also ask that if a computer can have that kind of a mind. When we inquire it in terms of epistemology we encounter some conflicting opinions. For example, functionalists<a id="reverse2"></a><sup> <a href="#2">$^2$</a></sup> say that mental states constituting the mind can broke down into functions, and can be reduced to computer softwares. This means, with simulating the right input-output correlation, we can create a function called “pain” regardless of how it is biologically implemented in our black(or I must say gray) box. On contrary, emergentists believe that mind is an emergent<a id="reverse3"></a><sup> <a href="#3">$^3$</a></sup> property which doesn’t exist individually but is observable in the whole system so can not easily be reduced to the functioning of the brain. In my opinion, we might assert that a complex emerging phenomenon can also be replicated in an artificial machine as well. This can leave us in a position that is favoring functionalists’ point of view obeying to the occam’s razor principle.

Do we have to simulate the exact human mind to get a conscious creature in the first place? Even if we did, how are we going to be sure about it? First of all thinking about thinking takes us back a long way to Descartes’ Cogito Argument<a id="reverse4"></a><sup> <a href="#4">$^4$</a></sup>. According to solipsist point of view, one can only be sure of his/her own thinking state does exist. But we assume all the people surrounding us do think just like denoted in the Wittgenstein's “beetle in a box”<a id="reverse5"></a><sup> <a href="#5">$^5$</a></sup> analogy. So I should assume a robot is thinking if it seems to be as well as I did take “people are thinking” for granted. Let me also look into the former question. We might also create a conscious artificial mind using a different path than ours. I want to quote Alan Chomsky at this, he says “Thinking is a human feature. Will AI someday really think? That's like asking if submarines swim. If you call it swimming then robots will think, yes.” However, according to John Searle, the inventor of famous Chinese room experiment<a id="reverse6"></a><sup> <a href="#6">$^6$</a></sup>, no matter what a computer seems to do, it is only capable of doing what it is programmed to and doesn’t have an awareness of what it is actually doing and lacks of intentionality. Another theory worth to mention in opposition to conscious machines is the existence of experience matters called “qualia”<a id="reverse7"></a><sup> <a href="#7">$^7$</a></sup>. It is originated from the claim that there must be a difference between knowing all the specifications of say a color and having the experience of seeing it, it is also addressed in Mary’s room<a id="reverse8"></a><sup> <a href="#8">$^8$</a></sup> analogy. These are some of the well-founded counter arguments to the idea of conscious Strong AI that is said to have domainless capabilities like people. In my opinion, we might be looking this issue from a practical standpoint in a near future. What I mean by practicality is human nature’s tendency to evaluating things with taking account the empirical and observable truths in spite of the much inner considerations just like the ones mentioned in Chinese or Mary’s room phenomenas.

After touching upon some mainly philosophical opinons we can talk about the most essential work on this subject; Alan Turing and the Turing Test. The reason Alan Turing is seen as the father of the artificial intelligence is that he could presciently mention and answer most of the discussions I refer above and more in his paper Computing Machinery and Intelligence<a id="reverse9"></a><sup> <a href="#9">$^9$</a></sup> in 1950s. He chose to come with an imitation game rather than giving definition to the question written in the headline. It is then called Turing Test and it briefly relies on whether a digital computer can be put in a humanoid position in the eye of an observer provided that the computer is unseen. It was a well-designed proposal for substitution to the main question but on the other hand it has some vulnerabilities. A few years ago, Eugene Goostman has convinced %33 of the judges that he is human because he introduced itself as a 13-year-old boy from the Ukraine<a id="reverse10"></a><sup> <a href="#10">$^{10}$</a></sup>. So knowing that it can be deceive-prone, we can say that we need for some alternative tests to apply. Winograd Schema Challenge<a id="reverse11"></a><sup> <a href="#11">$^{11}$</a></sup> is one of the most popular alternatives to Turing Test for instance. It is focused on measuring the AI’s commonsense reasoning. Because commonsense reasoning is an ability that is not only too easy for humans but also too complex for the computers, it can be though as the bottleneck of our main question. In other words, creating successful AIs that are proficient at doing interferences just as we do in our day-to-day lives is a major problem to solve. We can conclude that the advancement in this specific field will have a significant impact on how the realization of thinking robots phenomenon is likely to happen and our feelings about it.

Google’s Alpha Go’s defeating Lee Sedol<a id="reverse12"></a><sup> <a href="#12">$^{12}$</a></sup> and IBM’s Watson’s winning the game Jeopardy<a id="reverse13"></a><sup> <a href="#13">$^{13}$</a></sup> or self-driving cars are just a few examples of the many promising news especially for the future of “general” or say “strong” AI. However, even if they seem to be huge steps of coming general ai, they can indeed be counted as progresses made in a narrower fashion. As the domains of the improvements gets wider and merge, or the implementations and algorithms gets more complex, I believe that some day we will be living with our thinking robot friends like us. The only difference remaining might be the different sources of pulses between them and us; clock ticks or heart beats.

## References
<a id="1">[[1]](#reverse1)</a> https://www.merriam-webster.com/dictionary/thinking <br>
<a id="2">[[2]](#reverse2)</a> https://plato.stanford.edu/entries/functionalism/ <br>
<a id="3">[[3]](#reverse3)</a> https://plato.stanford.edu/entries/properties-emergent/ <br>
<a id="4">[[4]](#reverse4)</a> https://plato.stanford.edu/entries/descartes-epistemology/ <br>
<a id="5">[[5]](#reverse5)</a> http://www.open.edu/openlearn/history-the-arts/culture/philosophy/wittgensteins-beetle-the-box-analogy <br>
<a id="6">[[6]](#reverse6)</a> https://www.cambridge.org/core/services/aop-cambridge-core/content/view/S0140525X00005756 <br>
<a id="7">[[7]](#reverse7)</a> https://plato.stanford.edu/entries/qualia/ <br>
<a id="8">[[8]](#reverse8)</a> https://plato.stanford.edu/entries/qualia-knowledge/ <br>
<a id="9">[[9]](#reverse9)</a> https://www.csee.umbc.edu/courses/471/papers/turing.pdf <br>
<a id="10">[[10]](#reverse10)</a> http://time.com/2847900/eugene-goostman-turing-test/ <br>
<a id="11">[[11]](#reverse11)</a> http://commonsensereasoning.org/winograd.html <br>
<a id="12">[[12]](#reverse12)</a> https://www.theguardian.com/technology/2016/mar/15/googles-alphago-seals-4-1-victory-over-grandmaster-lee-sedol <br>
<a id="13">[[13]](#reverse13)</a> https://www.theguardian.com/technology/2011/feb/17/ibm-computer-watson-wins-jeopardy